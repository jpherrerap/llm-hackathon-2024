{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from uuid import uuid4\n",
    "from openai import OpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"question\": \"tweet\"},\n",
    "    id=1,\n",
    ")\n",
    "\n",
    "documents = [\n",
    "    document_1,\n",
    "]\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Configurar el text splitter con parámetros más apropiados para FAQ\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Reducido para mejor manejo de FAQs\n",
    "    chunk_overlap=200,  # Aumentado para mejor contexto\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")\n",
    "\n",
    "# Dividir los documentos manteniendo los metadatos\n",
    "all_splits = text_splitter.split_documents(documents)\n",
    "\n",
    "# Asegurarse de que cada split mantenga los metadatos originales\n",
    "for split in all_splits:\n",
    "    # Asegurarse de que los metadatos contengan tanto la pregunta como la respuesta\n",
    "    if 'question' not in split.metadata or 'answer' not in split.metadata:\n",
    "        original_doc = next(d for d in documents if d.metadata['question'] == split.metadata['question'])\n",
    "        split.metadata = original_doc.metadata\n",
    "    split.id = str(uuid4())  # Asignar un nuevo ID único a cada split\n",
    "\n",
    "client = OpenAI(\n",
    "    # base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"), # TODO: Cambiar por GROQ_API_KEY\n",
    ")\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    # client=client,\n",
    ")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"example_collection\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_langchain_db\",  # Where to save data locally, remove if not necessary\n",
    "    create_collection_if_not_exists=True,\n",
    ")\n",
    "\n",
    "# Crear y persistir la base de datos vectorial\n",
    "knowledge_db = vector_store.from_documents(\n",
    "    documents=all_splits,\n",
    "    embedding=embeddings,\n",
    "    collection_name=\"faq-collection\",\n",
    "    persist_directory=\"./chroma_langchain_db\",\n",
    "    ids=[doc.id for doc in all_splits]  # Pasar los IDs explícitamente\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
